{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "starter_nn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "baBE1ItX9lPA",
        "VBZa2IBM95gL",
        "2bQ4LA-hLDuA"
      ],
      "authorship_tag": "ABX9TyPTzkMLkq2vixR9FL9dKvtf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EverardoG/ml_comprobofinal/blob/net/starter_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baBE1ItX9lPA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eozeDZVIOQCY"
      },
      "source": [
        "\"\"\"\n",
        "Handle imports in one standard location\n",
        "\n",
        "Some of these may not be necessary\n",
        "I copied them over from a different ml project\n",
        "\"\"\"\n",
        "import cv2                           # Image handling\n",
        "import io                            # Handling zip object byte files\n",
        "import json\n",
        "import os\n",
        "import time                          # Timer for image loading\n",
        "import torch                         # Main ML Library\n",
        "import zipfile                       # Zip file nterfacing\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt      # Plotting & Visualization\n",
        "import numpy as np                   # Matrix handling\n",
        "import pandas as pd                  # Data storage & frameworks\n",
        "\n",
        "from google.colab import files\n",
        "from PIL import Image                # Image handling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn\n",
        "from torch.autograd import Variable  # Data class for nn training and testing\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # Class for creating random train/test datasets\n",
        "import pickle # for saving arbitrary objects\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtSScT1A9sHs"
      },
      "source": [
        "# Define Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHnrJJv6OSLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd7cf33-1301-40d2-b202-ed3447dbb028"
      },
      "source": [
        "class StarterNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    # Not sure what this does - It's from the pytorch docs\n",
        "    super(StarterNN, self).__init__()\n",
        "\n",
        "    # Set a verbosity for logging\n",
        "    self.verbose = 0\n",
        "  \n",
        "    # # Defining an activation function\n",
        "    # self.activation_func = torch.nn.ReLU()\n",
        "\n",
        "    # We only have 3 features (x, y, v) : Position and velocity of the ball\n",
        "    # and 1 output: v_N : velocity of the Neato\n",
        "    # TODO: Add bias term that's just a 1 (can add that into linear layer instead of encoding as input... maybe)\n",
        "    input_size = 3\n",
        "    fc1_size = 1\n",
        "\n",
        "    # fc1 stands for Fully Connected Layer 1\n",
        "    self.fc1 = nn.Linear(input_size, fc1_size)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    # Run training data through first fc layer\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # Put output through our activation function to add non-linearity\n",
        "    # x = self.activation_func(x)\n",
        "    return x\n",
        "\n",
        "  def getLossFunctionAndOptimizer(self, learning_rate):\n",
        "    # Loss function\n",
        "    loss = nn.MSELoss()\n",
        "    # TODO: Use squared loss for this. Figure out what this is in. Don't use cross entropy\n",
        "\n",
        "    # Optimizer, self.parameters() returns all the Pytorch operations that are attributes of the class\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    # optimizer is probably fine\n",
        "\n",
        "    return loss, optimizer\n",
        "\n",
        "starter_net = StarterNN()\n",
        "print(starter_net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StarterNN(\n",
            "  (fc1): Linear(in_features=3, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBZa2IBM95gL"
      },
      "source": [
        "# Define Simulation For Generating Fake Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "civEqZ2oAUM_"
      },
      "source": [
        "\"\"\"\n",
        "Columns for data are as follows: x, y, v_B, v_N\n",
        "\"\"\"\n",
        "\n",
        "def runSimulation(x, y, v_B, v_N, dt = 0.1, max_steps = 100, sim_verbosity = 1):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      x: Initial x position of the ball relative to the robot\n",
        "      y: Initial y position of the ball relative to the robot\n",
        "      v_B: Initial velocity of the ball\n",
        "      v_N: Initial velocity of the Neato\n",
        "      max_steps: Maximum number of steps to run simulation\n",
        "      sim_verbosity: How verbose to be in printing\n",
        "\n",
        "    Returns:\n",
        "      data: numpy array of data collected from simulated run\n",
        "    \"\"\"\n",
        "\n",
        "    # Run simulation for at a maximum of max_steps\n",
        "    for num_step in range(max_steps):\n",
        "        # Step x and y forward\n",
        "        x = x - v_N * dt\n",
        "        y = y - v_B * dt\n",
        "\n",
        "        # Stop the run if the ball has passed the robot\n",
        "        if y < 0:\n",
        "          if sim_verbosity >= 1: print(\"Ball passed robot\")\n",
        "          break\n",
        "\n",
        "        # TODO: Check if this is actually linear\n",
        "        # Change Neato velocity accordingly\n",
        "        if -1 < x < 0:\n",
        "          if sim_verbosity >= 3: print(\"Right\")\n",
        "          v_N = 0.2\n",
        "        elif 0 < x < 1:\n",
        "          if sim_verbosity >= 3: print(\"Left\")\n",
        "          v_N = -0.2\n",
        "        else:\n",
        "          if sim_verbosity >= 3: print(\"Stop\")\n",
        "          v_N = 0.0\n",
        "        \n",
        "        # Package all of our state information\n",
        "        new_data = np.array([x, y, v_B, v_N])\n",
        "\n",
        "        if sim_verbosity >= 2: \n",
        "            print(x,\" | \", y, \" | \", v_B, \" | \", v_N)\n",
        "\n",
        "        # Initialize data if not already initialized\n",
        "        # Otherwise update the existing data\n",
        "        if num_step == 0:\n",
        "            data = new_data\n",
        "        else:\n",
        "            data = np.vstack((data, new_data))\n",
        "\n",
        "    # Let us know if the ball never passed the robot\n",
        "    if y > 0:\n",
        "        if sim_verbosity >= 1: print(\"Ball never passed robot\")\n",
        "\n",
        "    # Let us know how many steps the simulation ran for\n",
        "    if sim_verbosity >= 1: print(\"Simulation ran for \", num_step + 1, \"steps\")\n",
        "\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bQ4LA-hLDuA"
      },
      "source": [
        "# Generate Data Based on Simulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2-LCkhgDJVv"
      },
      "source": [
        "# Sweep over different starting x positions, y positions and ball velocities for simulated data\n",
        "\n",
        "first_run = True\n",
        "\n",
        "# x varies from -1.5 to 1.5 m\n",
        "for init_x in np.linspace(-1.5, 1.5, 10):\n",
        "    # y varies from 1.0 to 2.0 m\n",
        "    for init_y in np.linspace(1.0, 2.0, 10):\n",
        "        # v_B varies from 0.1 to 1.0\n",
        "        for init_v_B in np.linspace(0.1, 1.0, 10):\n",
        "          # Neato velocity in initial step is arbitrary\n",
        "          new_data = runSimulation(init_x, init_y, init_v_B, 0.0, sim_verbosity=0)\n",
        "\n",
        "          # Initialize data structure on first run\n",
        "          if first_run:\n",
        "              sim_data = new_data\n",
        "              first_run = False\n",
        "          \n",
        "          # Concatenate data on following runs\n",
        "          else:\n",
        "              sim_data = np.vstack((sim_data, new_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs3jMsVcKc7Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a247ad-78c8-4c3e-b804-1eff577ef098"
      },
      "source": [
        "# Check how much data we have\n",
        "print(sim_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(38440, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLUF6EDZQW2I"
      },
      "source": [
        "## Partition Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKe4WLoLNw2A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e628ca-c019-4435-b224-cb0b522de8bd"
      },
      "source": [
        "\"\"\"\n",
        "Partition data into x_data and y_data\n",
        "\n",
        "X_data contains x, y, v_B\n",
        "y_data contains v_N\n",
        "\"\"\"\n",
        "\n",
        "# Organize data into X and y\n",
        "X_data = sim_data[:, :3]\n",
        "print(\"Shape of x data: \", X_data.shape)\n",
        "y_data = sim_data[:,3:]\n",
        "print(\"Shape of y data: \", y_data.shape)\n",
        "\n",
        "# Split data into training and testing\n",
        "X_train , X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.33, random_state = 42)\n",
        "print(\"X_train: \", type(X_train), X_train.shape)\n",
        "print(\"y_train: \", type(y_train), y_train.shape)\n",
        "print(\"X_test:  \", type(X_test), X_test.shape)\n",
        "print(\"y_test:  \", type(y_test), y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x data:  (38440, 3)\n",
            "Shape of y data:  (38440, 1)\n",
            "X_train:  <class 'numpy.ndarray'> (25754, 3)\n",
            "y_train:  <class 'numpy.ndarray'> (25754, 1)\n",
            "X_test:   <class 'numpy.ndarray'> (12686, 3)\n",
            "y_test:   <class 'numpy.ndarray'> (12686, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6dgpiTGyoy-"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FsIkCC80BNf"
      },
      "source": [
        "## Run the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nfg_Ia7fyu29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff58dac-092f-49d3-b767-945bba0289d4"
      },
      "source": [
        "# Instantiate the model and put it in training mode\n",
        "net = StarterNN()\n",
        "net.train()\n",
        "net.verbose = 0\n",
        "\n",
        "# Training Session Parameters\n",
        "num_epochs = 10000\n",
        "learning_rate = 0.001\n",
        "# batch_size = 50\n",
        "\n",
        "# Set up optimizer for gradient descent\n",
        "lossFunction, optimizer = net.getLossFunctionAndOptimizer(learning_rate)\n",
        "\n",
        "# Set up data for input into net\n",
        "X_train_var = Variable(torch.tensor(X_train.astype(np.float32)))\n",
        "X_test_var = Variable(torch.tensor(X_test.astype(np.float32)))\n",
        "y_train_var = Variable(torch.tensor(y_train.astype(np.float32)))\n",
        "y_test_var = Variable(torch.tensor(y_test.astype(np.float32)))\n",
        "\n",
        "grad_magnitudes = []\n",
        "\n",
        "# Go through all the epochs\n",
        "for epoch in range(num_epochs):\n",
        "  # Clear the gradient\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # Forward pass input data into \n",
        "  y_pred = net(X_train_var)\n",
        "  loss = lossFunction(y_pred, y_train_var)\n",
        "  loss.backward()\n",
        "  optimizer.step()    # Does the update\n",
        "\n",
        "  for name, param in net.named_parameters():\n",
        "    if name == 'fc1.weight':\n",
        "      grad_magnitudes.append(np.abs(param.grad.numpy()).mean())\n",
        "\n",
        "  if epoch % 1000 == 0:\n",
        "    print(\"epoch\", epoch)\n",
        "    for name, param in net.named_parameters():\n",
        "      print(name, \"value\", param.data, \"gradient\", param.grad)\n",
        "\n",
        "  # print(getAccuracyQuick(net, X_test_var, y_test_var))\n",
        "  # print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "fc1.weight value tensor([[ 0.1858, -0.3416,  0.2812]]) gradient tensor([[ 0.5063, -0.9246, -0.2886]])\n",
            "fc1.bias value tensor([-0.2774]) gradient tensor([-0.9158])\n",
            "epoch 1000\n",
            "fc1.weight value tensor([[-0.0336, -0.0193,  0.1435]]) gradient tensor([[-1.9011e-05, -2.0187e-02,  1.8171e-02]])\n",
            "fc1.bias value tensor([-0.0408]) gradient tensor([-0.0079])\n",
            "epoch 2000\n",
            "fc1.weight value tensor([[-0.0335,  0.0067,  0.0151]]) gradient tensor([[-6.6687e-07,  7.6705e-04,  1.0607e-03]])\n",
            "fc1.bias value tensor([-0.0116]) gradient tensor([-0.0020])\n",
            "epoch 3000\n",
            "fc1.weight value tensor([[-0.0335,  0.0011,  0.0022]]) gradient tensor([[-6.3106e-08,  1.6564e-04,  6.8437e-05]])\n",
            "fc1.bias value tensor([-0.0013]) gradient tensor([-0.0002])\n",
            "epoch 4000\n",
            "fc1.weight value tensor([[-0.0335,  0.0002,  0.0010]]) gradient tensor([[-3.3734e-08,  3.9040e-06,  1.5879e-06]])\n",
            "fc1.bias value tensor([-3.0293e-05]) gradient tensor([-5.3408e-06])\n",
            "epoch 5000\n",
            "fc1.weight value tensor([[-0.0335,  0.0002,  0.0010]]) gradient tensor([[-1.4835e-08,  6.1828e-09,  2.5980e-09]])\n",
            "fc1.bias value tensor([2.6835e-07]) gradient tensor([-7.4215e-09])\n",
            "epoch 6000\n",
            "fc1.weight value tensor([[-0.0335,  0.0002,  0.0010]]) gradient tensor([[-4.2449e-09, -1.1523e-09, -4.0272e-10]])\n",
            "fc1.bias value tensor([3.1471e-07]) gradient tensor([-1.8044e-09])\n",
            "epoch 7000\n",
            "fc1.weight value tensor([[-0.0335,  0.0002,  0.0010]]) gradient tensor([[-4.2577e-09, -4.7518e-10, -2.6720e-10]])\n",
            "fc1.bias value tensor([3.1835e-07]) gradient tensor([-5.5297e-10])\n",
            "epoch 8000\n",
            "fc1.weight value tensor([[-0.0335,  0.0002,  0.0010]]) gradient tensor([[-4.2868e-09, -5.3703e-10, -2.6720e-10]])\n",
            "fc1.bias value tensor([3.1822e-07]) gradient tensor([-5.5297e-10])\n",
            "epoch 9000\n",
            "fc1.weight value tensor([[-0.0335,  0.0002,  0.0010]]) gradient tensor([[-4.2286e-09, -5.3703e-10, -2.6720e-10]])\n",
            "fc1.bias value tensor([3.1820e-07]) gradient tensor([-5.5297e-10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SRmbChQgB7g",
        "outputId": "2ca24aec-4a77-4da0-879a-200b8d63abd5"
      },
      "source": [
        "X_fake = Variable(torch.tensor(np.array([0.5, 2.0, 0.4]).astype(np.float32)))\n",
        "V_neato = net(X_fake)\n",
        "print(V_neato)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0159], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckO8xVkb2Ac7"
      },
      "source": [
        "# Validate against a Linear Regression Model from Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8dkNk1I2FWX",
        "outputId": "588dbcd8-4567-49a0-f864-9b14ca200492"
      },
      "source": [
        "# Run linear regression with \n",
        "np.linalg.lstsq(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[-0.03352841],\n",
              "        [ 0.00021674],\n",
              "        [ 0.00095321]]),\n",
              " array([283.76834144]),\n",
              " 3,\n",
              " array([172.76302836, 162.07371041,  51.9319929 ]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuLEeMvs26Pt",
        "outputId": "aa3d622e-bd42-4ec1-c1a8-6e3ec7138e33"
      },
      "source": [
        "# Add a bias term\n",
        "X_train_bias = np.hstack((X_train, np.ones((X_train.shape[0],1)) ))\n",
        "# print(X_train_bias.shape)\n",
        "\n",
        "X_train_sad = X_train_bias[:,[1,2,3]]\n",
        "print(X_train_sad.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25754, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrfUjd3E3fiO",
        "outputId": "158fe5dd-73c8-4585-b094-bca9e7328de1"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uujOJxH5pwD",
        "outputId": "e6939770-93ec-4852-811d-53e196a1a761"
      },
      "source": [
        "np.var(y_train)*y_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "317.3165690766484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAx-NTBB5pt5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ULVUgD2dy-",
        "outputId": "8850cee4-ac4f-45ef-ec44-8a85d4987d68"
      },
      "source": [
        "print(y_train)\n",
        "print(max(y_train))\n",
        "print(min(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. ]\n",
            " [0.2]\n",
            " [0. ]\n",
            " ...\n",
            " [0. ]\n",
            " [0. ]\n",
            " [0.2]]\n",
            "[0.2]\n",
            "[-0.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEUMALHN0wEi"
      },
      "source": [
        "\"\"\"\n",
        "Possibly look into later\n",
        "\n",
        "# Create samplers for dataloaders\n",
        "sampler_train = SubsetRandomSampler(np.arrange(len(data_train), dtype=np.float64))\n",
        "sample_test = SubsetRandomSampler(np.arrange(len(data_teset), dtype=np.float64))\n",
        "\n",
        "# Create TensorDataLoaders for getting data out of TensorDatasets\n",
        "loader_train = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=2)\n",
        "loader_test = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "# Variables for storing metrics\n",
        "grad_magnitudes = []\n",
        "losshist_train_x = []\n",
        "losshist_train_y = []\n",
        "losshist_test_x = []\n",
        "losshist_test_y = []\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}